# OS 



#### **멀티 스레드는 멀티 프로세스에 비해 상당한 이점을 가진다**

1. **컨텍스트 스위칭(Context Switching) 시에 공유 메모리 만큼의 시간(자원) 손실이 줄어든다.** 

​    : 프로세스 간의 컨텍스트 스위칭시 단순히 CPU 레지스터 교체 뿐만이 아니라 RAM과 CPU사이의 캐쉬메모리에 대한 데이터 까지 초기화 되므로 상당한 부담이 발생한다. 

2. **Stack을 제외한 모든 메모리를 공유**하기 때문에 global(전역), static(정적) 변수 그리고 new, malloc에 의한 모든 자료를 공유할 수가 있다. 

​    : 이는 프로세스간 통신(ex.pipe)과 같이 복잡한 과정을 거치지 않고 보다 효율적인 일처리가 가능하다는 것을 뜻한다. (핸들 테이블과 환경변수는 덤이다.) 

=> 멀티 프로세싱은 **여러가지의 프로그램을 동시에 작업(멀티 태스킹)**하는 경우나 **서로 별도의 작업공간을 지니는 작업을 지닌 프로그램의 실행**에 용이하다. (혹은 동기화 성능 이슈가 민감한 프로그램을 수행 ) 

=> 멀티 스레드는 한 프로그램 내에 여러 가지의 하위 Task가 있을 경우, 이 Task 간의 병행 실행을 돕는측면에서 용이하다. (작업공간을 공유하고, 작업의 시간복잡도가 높은 경우에 적절하다.) 

## 3. 프로세스 

- 프로세스는 실행되고 있는 하나의 프로그램을 의미 

- 하나의 시스템 = 여러 프로세스 집합 

- 프로세스의 구조는 다음과 같다.

  - **text section** (현재 활동에 대한 PC값 , 레지스터 콘텐츠 들을 포함) 
  - **Program Counter 값**(현재 실행중인 프로그램의 명령 위치를 알려주는 값) 
  -  **process stack**(임시 데이터 ; 함수 파라미터, 리턴주소, 지역변수 등) 
  - **data section** : 전역 변수를 포함하는 영역
  - **heap** : 프로세스 runtime 중에 동적으로 할당되는 메모리 영역

- 프로세스의 상태는 총 5단계로 

  - `new` : 생성상태 
  - `ready` : 프로세스가 프로세서(CPU)에 의해 자원이 할당되기를 기다리는 상태
  - `running` :  명령들의 실행되는 상태. **프로세스 스케줄러**에 의해 ready->running 으로 디스패치된다.
  - `waiting` : 프로세스가 I/O 나 event 수신과 같은 어떤 이벤트가 일어나기를 기다리는 상태. 입력 등의 이벤트 이후 `ready` 로 돌아간다.
  - terminated : 프로세스 실행 마친 상태. 
  - 한 프로세서에서는 보통 한 프로세스만 running상태를 유지한다. 대부분의 프로세스는 ready/waiting 상태를 유지한다.

  #### PCB (Process Control Block)

  - 프로세스에 관한 구체적인 정보를 지닌다.

  - 프로세스 상태(new/ready/running/waiting/terminated..)를 보유
  - 프로그램 카운터(다음에 실행할 명령어의 주소를 나타내는 값)를 보유

  

#### Process 0과 1의 작업간 전환

- P0 실행중에 인터럽트/시스템 콜 발생시 -> PCB0에 P0의 상태를 저장한다. 
- PCB1로부터 상태를 다시 load 한다. 그러면 P1이 ready 상태에서 다시 running 상태로 작업을 수행한다.
- 다시  P1에서 인터럽트/시스템콜 발생시 -> PCB1에 상태를 저장하고 프로세서는 idle 상태로 변한다. 
- 그러면 PCB0으로부터 P0의 상태를 다시 load하고 P0이 실행된다.



#### 프로세스 스케줄링

- 멀티 프로그래밍에서 CPU의 utilization을 극대화 하기 위해 time sharing을 사용한다.  
- time sharing은 프로세스들간에 cpu를 빈번하게 스위치시켜주어 사용자의 각 프로그램들의 작동 중에 상호작용을 할 수 있도록 해준다.

#### 스케줄링 큐

- 프로세스들이 시스템에 들어오면 일단 프로세스들은 `job queue`에 보내진다.
- ready queue : 프로세스들은 메인 메모리속에 존재하며, 실행되기 전까지 `ready/waiting` 상태로 레디큐에 보관된다.
- device queue : 특정 I/O device를 위해 대기하는 프로세스들의 리스트를 말한다.



#### 프로세스 스케줄러

- 프로세스는 lifetime 동안 다양한 스케줄링 큐 사이에서 옮겨다닌다.
- long-term scheduler : 프로세스들을 **대용량 저장장치에서 선택**하고, **실행을 위해 메모리에 옮기는 스케줄러**. 새로운 프로세스 생성-> 다음 프로세스 생성 및 선택까지 (수초~수분) 소요
- short-term scheduler : 실행을 위해 **메모리에 대기중인** 프로세스들로부터 프로세스를 선택하고, 프로세스 가운데 하나를 cpu에 할당하는 스케줄러. CPU를 위해 새로운 프로세스를 빈번하게 선택함.
- I/O-bound process : 연산보다 I/O에 프로세스의 상당 시간을 할애하는 프로세스
- CPU-bound process : I/O 연산은 적고, 연산에 시간을 많이 할애하는 프로세스



**Context Switch**

- 프로세스 실행중에 interrupt 발생시 시스템은 이후의 작업 지속을 위해 현재 CPU에서 **작동중인 프로세스의 context를 저장**한다.
- context : **cpu에서 작업한 프로세스의 진행상태**(the PCB of the process)를 의미. **CPU 레지스터 값**과 **프로세스 상태,** 메모리 관리 정보 등을 포함

---

----



## 4 스레드 (sub-process)

- 한 프로그램 내에서 실행되는 흐름의 단위를 일컫음. 

- 스케쥴러에 의해 독립적으로 관리가능하다. 프로세스와 달리 code 와 Data를 공유한다.

- 병렬처리가 가능하다.

- 하나의 스레드는 프로세스가 한번에 하나의 task 실행만 가능하도록 한다. 유저는 문자 타이핑과 스펠 체킹을 동일 프로세스에서 동시에 진행할 수 없다.

- #### Thread구성요소 

  - Thread ID
  - PC
  - Register set
  - Stack 

- 같은 프로세스에 속한 다른 스레드와 공유하는 자원들

  - **code**
  - **data** section
  - open 파일이나 signal 같은 **OS 리소스들**





### 다중 스레드 모델 장점

1. ##### 응답성 

   - 앱의 일부가 blocked되거나 앱이 긴 작업 수행하더라도 프로그램의 수행이 계속가능하여 사용자에 대한 응답성 증가

2. ##### 자원공유

   - 프로세스 : `공유메모리`와 `메시지 전달 기법`을 통해서만 자원을 공유한다.
   - 스레드 : 자동적으로 **소속된 프로세스내** 자원들과 메모리를 **공유.**
   - 같은 주소공간 내 여러 개의 다른 작업하는 스레드 보유 가능

3. ##### 경제성

   - 프로세스 생성을 위한 메모리/자원 할당 비용 **>** 스레드 생성 & context-switch 비용

4. ##### 규모 적응성

   - **각각의 스레드를 다른 프로세스에서 병렬수행 가능**하므로 멀티프로세서 아키텍처에서 더욱 효과적.



#### **병렬 실행** **vs** **병행 실행** 

**병렬성(멀티코어)** 

-  <u>하나 이상의 태스크를 동시에 수행</u>할 수 있는 시스템. 

- ex ) single core, 4 thread : 한 코어가 오직 하나의 스레드만 실행. 
  - 따라서 병행성이 단순하게 스레드의 실행이 시간에 따라 교대로 실행됨을 의미. (병행 실행)

**병행성(멀티쓰레드)** 

- <u>스레드들이 병렬적으로 실행</u>될 수 있는 것을 의미. 모든 태스크가 진행하게끔 함으로써 하나 이상의 태스크를 지원. 

- ex) 4 core, 4 thread : 4개의 코어가 개별 스레드를 각 코어에 배정받아 병렬적으로 실행 (병렬 실행)



#### **[ 커널 모드와 유저 모드 ]**

- 메모리 영역은 사용자에 의해서 할당되는 메모리 공간인 **유저 영역**과 운영체제라는 하나의 소프트웨어를 실행시키기 위해서 필요한 메모리 공간인 **커널 영역**으로 나뉜다.
- **사용자가 사용하는 메모리 영역**은 유저 영역이지만 C언어는 메모리 참조가 용이하기 때문에 안정성 제공 측면에서 커널 모드와 유저 모드가 사용된다.
- **기본적으로 유저 모드로 동작**하다가 Windows **커널이 실행되어야 하는 경우에 커널 모드로의 전환**이 일어난다.
- 커널 모드와 유저 모드의 차이는 **유저 모드에서 동작할 때 커널 영역으로의 접근이 금지된다**. <u>커널 모드일 때는 모든 영역의 접근이 허용</u>된다.

#### **[ 커널 레벨 쓰레드와 유저 레벨 쓰레드 ]** 

- 커널 레벨 쓰레드와 유저 레벨 쓰레드는 **생성 주체가 누구냐에 따라 구분**된다. 
- 프로그래머 요청에 따라 <u>쓰레드를 생성</u>하고 <u>스케줄링</u>하는 주체가 **커널**이면 커널 레벨(Kernel Level) 쓰레드라고 한다. 

- **커널이 쓰레드 모델을 지원하지 않거나** 제공하는 쓰레드 모델이 마음에 들지 않을 경우, **커널에 의존적이지 않은 형태로 쓰레드의 기능을 제공하는 라이브러리를 활용**할 수 있는데 이러한 방식으로 제공되는 쓰레드가 **유저 레벨(User Level) 쓰레드**이다. 

#### 커널레벨 스레드 

- **Kernel-level에 있는 Threads는 독립적으로 스케줄**되므로 특정 Thread에서의 Blocking이 process로 전파되지 않습니다.

- 그래서 **Blocking System Calls를 이용할 수** 있습니다. 또한 **각 Threads끼리 Signal을 주고 받을 수** 있습니다. 

  ##### [커널 레벨 쓰레드의 장점]

  - <u>커널이 직접 제공</u>해 주기 때문에 안정성과 다양한 기능이 제공된다.
  - 멀티 프로세서를 활용가능하다.
  - **Kernel-level에 있는 Threads는 독립적으로 스케줄**되므로 특정 Thread에서의 Blocking이 process로 전파되지 않는다.
  - windows, unix, linux 에서 사용된다.

  ##### [커널 레벨 쓰레드의 단점]

  - 커널 레지스터를 복구하는 등의 **스레드 컨텍스트 스위치**가 필요하다. 
  - <u>유저 모드에서 커널 모드로의 전환이 빈번하게 이뤄져 성능 저하가 발생</u>한다. 
  - 즉, 상대적으로 느리다.

#### 유저레벨 스레드

- 응용 프로그램과 Link/Load가 되는 라이브러리로 구현된다.
- 이 라이브러리는 동기화, 스케줄링 기능을 모두 담고 있다.  

- **커널과 분리되어 커널레벨에서는 인식이 되지 않는다**.

  - 커널에서는 단지 싱글 프로세스로 인식

- 사용자 레벨 스레드의 예 : Java jvm의 thread, Linux의 스레드 일부 

  ##### [유저 레벨 쓰레드의 장점]

  - <u>커널은 쓰레드의 존재조차 모르기 때문에 모드 간의 전환이 없고 성능 이득이 발생</u>한다. 

  ##### [유저 레벨 쓰레드의 단점]

  -  <u>하나의 스레드가 커널에 의해 블로킹 되면 프로세스 전체가 블로킹</u>되고, 이를 해결하려면 프로그래밍이 어려워지고 <u>커널 레벨 쓰레드에 비해 결과 예측이 어려워진다</u>. 
  - **프로세스내의 한 쓰레드가 커널로 진입하는 순간, 나머지 쓰레드들고 전부 정지**된다. <u>커널이 유저레벨 쓰레드의 존재를 알지 못하므로 불가피한 현상</u>이다. 

---

### 다중 스레드 모델 종류 

#### Many-to-One Model (M user thread : 1 kernel thread)

- **특징** : 많은 사용자 수준 스레드를 하나의 커널 스레드로 Mapping. 
  - 스레드 관리는 user 공간의 thread Library에 의해 수행되므로 효율적.
  - **한 스레드가 봉쇄형 System call**을 할 경우, **전체 프로세스가 blocked**된다.
  - 한번에 하나의 스레드만이 커널에 접근, 다중 스레드가 다중코어 시스템에서 병렬 실행이 불가.
  - 현대에 거의 사용 x



#### One-to-One Model (1 user thread : 1 kernel thread)

- **특징** : 각 사용자 스레드를 각각 하나의 커널 스레드로 Mapping.
  - **하나의 스레드가 봉쇄형 System call을 해도 다른 스레드가 실행될 수 있음** — > **Many to 1보다 병렬성 높음** 
- **단점**
  - **user level 스레드 생성시, 그에 따른 커널 스레드를 생성**해야 한다.  
    -  **커널 스레드 생성 오버헤드** 발생
    - 따라서 시스템에 의해 지원되는 스레드 수를 제한함. 
    - Windows, Linux계열 OS



#### Many-to-Many Model 

- 특징 : 여러 개의 user-level 스레드를 그보다 작은 수 혹은, 같은 수의 커널 스레드로 **multiplex** 한다.  
  - 커널 스레드의 수는 어플리케이션 프로그램이나 특정 기계에 따라 결정됨.
  - 응용 프로그램이 싱글 프로세서보다 멀티 프로세서에서 더 많은 커널 스레드를 할당 받음.

​      cf. Two-Level Model

​     : Many-to-Many 모델의 변형. 한 user 스레드가 하나의 커널 스레드에만 연관되는 것을 허용. 

 

#### 암묵적 스레드 (Thread Pool )

- 사용 목적 :  **매 태스크 생성/종료마다 스레드를 생성/폐기 하는 비용**이 크다. + 시스템에서 동시 실행할 수 있는 **최대 스레드 수의 한계 지정** 필요성
- ***프로세스를 시작할 때*** <u>아예 일정수의 스레드를 미리 풀로 만들어두는 것</u>. 평소에 대기하다가 요청에 따라 스레드를 할당한다.  
- 요청의 처리가 끝나면 스레드는 다시 풀로 돌아가서 다음 작업을 기다림 
- 풀의 스레드가 모두 할당되었다면, 서버는 가용 스레드가 하나 생길 때 까지 기다린다. 

##### [ Thread Pool 장점 ] 

- 새 스레드를 만들어 주기보다 기존에 생성된 스레드로 서비스해주는 것이 더 빠름 
- **스레드 풀은 임의 시각에 존재할 수 있는 스레드 개수에 제한**을 둔다 -> **많은 수**의 스레드를 **병렬처리할 수 없는 시스템에 도움**이 됨. 
- 태스크를 생성하는 방법을 태스크로부터 분리하여 태스크 실행 방식을 다양하게 할 수 있다. 태스크를 일정 시간 후에 실행되도로고 스케줄, 주기적으로 실행 등 

#### 

## 5. CPU 스케줄링

- OS는 프로세스 스케줄이 아니라, **실질적으로 커널 level 스레드를 스케줄**한다.

- Single Processor 시스템에서는 한 순간에 오직 하나의 프로세스만이 실행

  - 나머지 프로세스는 cpu가 자유 상태가 되어 다시 스케줄 될 수 있을 때까지 대기

- **다중 프로그래밍에 대한 기본 아이디어**

  - 하나의 프로세스는 어떤 입출력 요청이 완료되기를 기다려야만 할 때까지 실행됨. 

  - 이 입출력 대기 시간동안 CPU는 유휴상태가 되고 다른 어떤 작업도 수행하지 못하게 됨. 

  -  따라서 어떤 프로세스가 대기해야 할 경우, OS는 CPU를 그 프로세스로부터 회수해서 다른 프로세스에 할당 

#### CPU 스케줄러 

- CPU 유휴상태 될 때마다 OS는 `Ready Queue`에서 프로세스를 하나 선택하여 실행(cpu 자원을 할당한다.)

- short term scheduler(CPU 스케줄러)에 의해 수행된다.
- `Ready Queue` : FIFO Queue, 우선순위 큐, 트리, 원형 링크드리스트 등으로 구현 가능.

### 선점 스케줄링 

1) 데이터가 다수의 프로세스에 의해 공유될 때 **경쟁 조건을 초래**할 수 있음. 

2) 데이터 **일관성 문제**도 발생 가능. (한 프로세스가 자료 갱신 중에 선점된 두 번째 프로세스가 실행 가능한 상태에서 데이터 read시) 

3) 운영체제 **커널 설계에 영향**을 줌.      (ch 5.6) 

​	ex. 시스템 호출 처리할 동안 프로세스 활동(입출력 큐와 같은 중요한 커널 자료 변경등을 포함) 중에 해당 프로세스가 선점되고 커널이 동일한 구조를 읽거나 변경하는 일이 발생한다면 시스템에 혼란을 초래한다.

- 원시적 해결방안 -> 문맥교환을 수행하기 전에 시스템 호출이 완료되거나 입출력 요구에 따른 blocking이 일어나기를 기다리는 방법을 사용. 

- but, 커널 자료구조가 비일관적인 상태에 있을 동안 커널이 해당 프로세스를 선점하지 않음. --> 커널 구조가 단순해짐. 

4) **Interrupt는 어느 시점에서건 발생 가능.** 

- 커널에 의해 항상 무시될 수 없기 때문에 Interrupt에 의해 영향받는 코드 부분은 반드시 **동시 사용으로부터 보호**되어야 함. 



#### CPU 스케줄링 결정이 가능한 4가지 상황

- 1) `run` -> `wai`t 전환될 때 ( I/O 요청이나 자식 프로세스 종료위해 wait 호출 할 때)

- 2) **interrupt 발생 시** : 프로세스가 `run` -> `ready` 상태 전환될 때 

- 3) **입출력 종료 시 :** 프로세스가 `wait` 상태 -> `ready` 상태로 전환될 때

- 4) 프로세스 종료시 

  1) 4)는 스케줄링 면에서 레디큐에 있는 새로운 프로세스가 반드시 선택되어야 한다. (non-preemptive or cooperative)

  2) 3)은 선점 스케줄링 방법이 적용 가능



#### 디스패처의 역할

- 디스패처 : CPU의 제어를 단기 수케줄러가 선택한 프로세스에게 주는 모듈을 의미한다.
- 1) **context-switching**
- 2) **사용자 모드로 전환** : multi-user 
- 3) 프로그램을 다시 시작하기 위해 **사용자 프로그램의 적절한 위치로 이동**

---



## 6. 스케줄링 알고리즘

#### 1) First-Come, First-Served Scheduling (선입 선처리 스케줄링)

- Ready Queue = FIFO 큐로 선입 선처리 방식

- convoy effect 발생이 단점 

  - 모든 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다려야 한다.
  - 평균대기시간이 종종 대단히 길어서 CPU 이용률이 저하된다.

  

#### 2) Shortest-Job-First Scheduling (최단 작업 우선 스케줄링)

- 각 프로세스에 `다음 CPU Burst Time 길이` 를 고려한다.

- CPU 이용가능시에 가장 작은  `다음 CPU Burst Time 길이` 를 가진 프로세스에게 자원을 할당

- 두 프로세스가 **동일한 길이의 다음 CPU burst를 가지면** 순위를 정하기 위해 **선입 선처리 스케줄링을 적용**

  ##### SJF 장점

  - 주어진 프로세스 집합에 대해 최소의 평균 대기 시간을 가진다.
  - 평균 대기시간이 줄어든다

  ##### SJF의 구현의 어려움

  - `다음 CPU 요청의 Burst Time 길이` 파악하기 어려움
  - 장기 스케줄링에서 자주사용
  - 단기 CPU 스케줄링 수준에서는 구현 불가.

##### 2-1) 선점형 SJF 알고리즘

- 이후 **도착하는 프로세스의 BurstTime 길이가 현재 실행중인 것보다 짧으면**, 그 프로세스는 현재 실행중인 프로세스를 대신하여 중간에 선점한다.

##### 2-2) 비선점형 SJF 알고리즘

- **현재 실행중인 프로세스가 자신의 CPU Burst를 끝내도록 허용**한 후에 다음 레디큐 내 프로세스의 최단 BurstTime 프로세스를 실행시킨다.

  

#### 3) 우선순위 스케줄링 (Priority Scheduling)

- 우선순위가 각 프로세스들에게 연관되어, **CPU는 가장 높은 우선순위의 프로세스에게 할당**된다.
- **우선순위가 같은 프로세스들은 FIFO 순**으로 순서를 정한다.
- **선점/비선점 스케줄링** 둘 다 가능 
- SJF도 Priority Scheduling의 한 예이다.

##### 우선순위 스케줄링 단점 - starvation 문제

- 낮은 우선순위로 ready 상태에서 CPU를 사용하지 못하고 무한히 대기하는 프로세스가 존재할 수 있음 



#### 4) Round-Robin 스케줄링

- Ready 큐는 **circular & FIFO 큐로 동작**
- FCFS 스케줄링과 유사하나, 시스템이 프로세스들 사이를 옮겨다닐 수 있도록 선점이 추가됨
- CPU 스케줄러는 Ready 큐의 첫번째 프로세스를 선택한다. 
- **시간 할당량을 먼저 정의**하여 자원을 할당받은 프로세스는 **해당 시간 할당량 만큼만 CPU를 사용**한다. 
- **할당 시간 후 인터럽트를 걸도록 timer가 설정**된다.
- case 1 ) 프로세스의 **CPU Burst Time <= Time slice** 
  - 스케줄러는 Ready Queue 내 다음 프로세스를 dispatch하여 진행
- case 2 ) 프로세스의 **CPU Burst Time > Time slice**
  - **Timer에 의해 interrupt, context-swithing 발생**하여 실행중인 프로세스는 **Ready큐의 꼬리에 넣는다**.

##### RR 스케줄링 유의사항

- Time slice가 크다면 RR = FCFS가 될 수 있다.
- 너무 작다면 빈번한 Context-switching으로 오버헤드 증가.



#### 5) 멀티레벨 큐 스케줄링 (다단계 큐 스케줄링)

- 프로세스들이 쉽게 상이한 그룹으로 분류될 수 있는 상황을 위해 프로세스를 구별한다. 프로세스들은 **시스템 진입 시 영구적으로 하나의 큐에 할당**되어 **다른 큐로 이동이 불가능.** 
- `대화형 프로세스(Foreground)`와 `일괄처리 프로세스(Background)`는 각각 요구되는 응답시간이 다르므로 스케줄링을 달리 처리한다.
- 대화형 프로세스가 보통 높은 우선순위

##### 다단계 큐 스케줄링 알고리즘 특징

- Ready 큐를 다수의 별도 큐로 분류. 

- 프로세스들이 메모리 크기, 프로세스의 우선순위 혹은 프로세스 유형과 같은 프로세스 특성에 따라 **한 개의 큐에 영구적으로 할당** 됨. 

- **각 큐**는 **자신의 스케줄링 알고리즘**을 지님. 

​          ex) foreground 큐 : RR 알고리즘 || background 큐 : FCFS알고리즘 

- **큐와 큐 사이에 스케줄링**도 반드시 필요

​         : 일반적으로 고정 우선순위의 선점형 스케줄링으로 구현 



#### 6) Multilevel Feedback Queue Scheduling (다단계 피드백 큐 스케줄링)

- 일반적으로 프로세스들은 시스템 진입 시 영구적으로 하나의 큐에 할당되어 다른 큐로 이동이 불가능. 

​     ex) foreground queue에서 background queue로 이동 불가 (= 그냥 다단계 큐 스케줄링) 

​     But, **프로세스**가 **큐**들 **사이를 이동할 수 있는 것을 허용**하는 것이 다단계 피드백 큐 

**MFQS 아이디어 (queue 사이 이동으로 aging 을 통한 starvation 예방을 구현)**

​     1. 프로세스들을 CPU burst 성격에 따라 구분 

​     2. 어떤 프로세스가 CPU 시간을 너무 많이 사용시, 낮은 우선순위의 큐로 이동 

​     3. 입출력 중심의 프로세스와 대화형 프로세스들은 높은 우선순위의 큐에 넣음. 

​     4. 낮은 우선순위 큐에서 너무 오래 대기하는 프로세스들은 높은 우선순위 큐로 이동.  



 **MFQS를 정의하는 매개변수**

​     1) 큐의 개수 

​     2) 각 큐를 위한 스케줄링 알고리즘 

​     3) 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법 (aging) 

​     4) 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법 (time quantum ) 

​     5) 프로세스가 서비스 필요로 할 때, 프로세스가 들어갈 큐를 결정하는 방법 





----



## 스레드 스케줄링

경쟁범위에 따라 2가지로 분류

#### 1) 프로세스-경쟁 범위 (Process-contention scope, PCS)

- **사용자수준**에서 동일한 프로세스에 **속한 스레드들 사이에서 CPU 경쟁**

#### 2) 시스템 경쟁범위 (System-"", SCS)

- CPU상에서 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해 **커널이 사용하는 경쟁범위** 





### 다중 프로세서 스케줄링

- 로드 셰어링 - 여러 개의 CPU사용가능할 때, 부하 공유가 가능하다. 대신 스케줄링이 복잡해진다.

##### 멀티프로세서 스케줄링에 대한 접근 방법      

 **- 비대칭 다중 처리** (*asymmetric multiprocessing*)

​     : 하나의 프로세서(master server)가 모든 스케줄링의 결정과 입출력 처리, 그리고 다른 시스템의 활동을 취급.  

​     : 다른 프로세서들은 다만 user code만을 수행. 

​     : 단지 한 프로세서만 시스템 자료구조를 접근하여 자료 공유의 필요성을 배제하므로 간단 ! 



 \- **대칭 다중 처리** *(symmetric multiprocessing, SMP)*

​     : 각 프로세서가 독자적으로 스케줄링 

​     : 모든 process는 공동의 Ready 큐에 존재하거나 각 프로세서마다 지닌 private Ready큐에 존재.  

​     : 각 프로세서의 스케줄러가 Ready 큐를 검사해서 실행할 프로세스를 선택함으로써 스케줄링이 진행.  

​     : **동기화 문제** 등 해결해야 





## 7. CPU 동기화

- #### **경쟁상황 (race condition)**

  - 두 개 이상의 프로세스가 동시에 동일한 자료를 접근하여 조작하고, 그 실행 결과가 접근이 발생한 특정 순서에 의존하는 상황. 
    - 한 순간에 하나의 프로세스만이 변수 counter를 조작하도록 보장해야 함.

  #### 크리티컬 섹션

  - 다중 프로그래밍 운영체제에서 **여러 프로세스가 데이터를 공유**하면서 수행될 때 **각 프로세스에서 공유 데이터를 액세스하는 프로그램 코드 부분**
  - 크리티컬 섹션에 한 프로세스가 액세스하고 있을 때는 다른 프로세스들은 절대로 그 데이터를 액세스하지 못하도록 하여야 한다.
  - 각 <u>프로세스는 크리티컬에 진입하려면 진입허가를 요청해야 함</u>

  ##### 임계구역 문제를 해결하기 위해서는 3가지 요건이 충족되어야 함

  - 상호배제 : 프로세스A가 임계구역 실행시 다른 프로세스들은 임계구역 실행 불가.
  - 진행 : 임계구역을 실행하는 프로세스가 없고, 임계구역에 진입하려는 프로세스들이 존재하면 누가 진입할지를 참여할 수 있다.
  - 한정된 대기 : 프로세스가 임계구역을 진입 요청하고 실제 진입까지 허용되는 대기시간은 무한하지 않음. <u>즉, 다른 프로세스들의 진입 횟수에 제한이 있음</u>

  ### 피터슨 해결방안 

  - **임계구역 문제에 대한 SW기반 해결책**
  - **임계구역(critical section)**과 **나머지구역(remainder section)**을 번갈아가며 실행하는 두 개의 프로세스로 한정

  ##### How to?

  - 프로세스는 `P0`과 `P1`로 번호매김 

    : 두 프로세스가 두 개의 데이터 항목을 공유하도록 하여 임계구역 문제를 해결한다. 

    : 편의상 Pi, Pj (j = 1-i) 

    ```c
    int turn; 
    boolean flag[2]; 
    ```

    - 변수 **turn** 은 임계구역으로 진입할 순번을 나타냄.  

    ​     ex)`turn == i `이면 프로세스 Pi가 임계구역에서 실행될 수 있다. 

    - **flag 배열** : 프로세스가 임계구역으로 진입할 준비가 되었다는 것을 나타낸다.  

    ​     ex) `flag[i] == true` 이면 이 값은 Pi가 임계구역으로 진입할 준비가 되었음을 의미. 

    ##### 임계구역으로 진입하기 위한 순서 

    1. Pi는 먼저 flag[i]를 참으로 만든다. 

    2. turn 을 j로 지정. 

    3. 프로세스 j가 임계구역으로 진입하기 원하면 진입이 가능해짐. 

    **Peterson's solution에서** **프로세스 Pi의 구조**

    ```c
    do {
         //1.entry section Pi가 임계구역 안으로 진입하고자 함.
         flag[i] = TRUE;     //Pi가 실행되고자 한다면
         turn = j;           //기존에 CS에 진입하던 Pj를 위해 turn = j로 설정.(Progress차원)
         while(flag[j]&&turn ==j);          	  
         //flag[j]==TRUE&&turn==j 일 동안 대기
         //2.critical section       //Pi가 CS로 진입
         //3.exit section          //Pi가 임계구역 밖으로 나감
      	 //Pj의 재진입을 위해 flag[i] =FALSE로 재지정.
         flag[i] = FALSE;                
    		 //4.remainder section 
    } while(TRUE);
    ```

    Peterson's solution에서 **프로세스 Pj의 구조**

    ```c
    do { 
         //1. entry section
    	   // Pj가 실행되고자 한다면 flag[j] =TRUE로 지정.
         flag[j] =TRUE;    
         // 기존에 CS에 진입하던 Pi를 위해 turn =i 로 지정(Progress 지원)
         turn = i;         
      	 // flag[i] ==TRUE && turn==i일 동안 대기
         while(flag[i] &&turn ==i);    
         //2. critical section    // Pj가 CS로 진입
         //3. exit section       // Pj가 임계구역 밖으로 나감.
         flag[j] ==FALSE;       // Pi의 재진입을 위해 flag[i] =FALSE로 재지정.
         //4. remainder section
    } while(TRUE);
    ```

### 동기화 하드웨어

- 임계구역에 대한 SW기반 해결책은 현대 컴퓨터 아키텍처에서 올바르게 동작하지 않음. 

- 커널 프로그래머와 응용 프로그래머가 사용가능한 HW부터 SW기만 API를 망라한 기법을 사용하여 임계구역 문제에 대한 해결책을 탐구 

  - 모든 해결책이  **LOCKING(락킹)**에 대한 가정, 즉 **CS 보호를 위한 락을 사용하는 것에 기반**을 둔다. 
  - SingleProcessor : No interrupt locking
  - MultiProcessor : interrupt locking 사용시 단점
    - 인터럽트의 사용불가능화 메시지가 모든 프로세서에 전달되므로 상당한 시간 할애.
    - 메시지 전달이 각 CS에 진입하는 것을 지연시켜 성능 저하
  - **MultiProcessor : test_and_set(), compare_and_swap()**
  - `test_and_set()` : 한 workd의 내용을 검사하고 변경하거나
  - `compare_and_swap()` : 두 word의 내용을 원자적으로(atomically) 교환(swap)할 수 있는 인터럽트되지 않는 하난의 단위로서 특별한 HW 명령어들을 제공

  ----

  

### Mutex Locks

- 하나의 자원을 통제하는데 사용됨
- 이진세마포어와 유사.

- 한 프로세스가 크리티컬 섹션(공유 데이터)을 액세스할 때는 다른 프로세스들은 그것을 사용하지 못하도록 하는 운영체제의 SW 기능
- 시스템의 어떠한 자원을 한 시점에서 한개의 프로세스만이 사용할 수 있도록 하는 것

- 임계구역 보호와 경쟁조건 방지 위한 기능. 

  - 임계구역에 들어가기 전에 반드시 lock을 획득,  임계구역 탈출 시 lock을 반환. 

- **mutex Lock**

  - acquire( )  : lock 획득 
  - release( )  : lock 반환 
  - available 변수 : lock의 가용 여부를 표시. 
  - lock이 사용가능하면 acquire( )  호출은 성공. lock은 곧 사용불가 상태가 된다.
  - 사용불가상태의 lock을 획득하려고 시도하는 프로세스는 lock이 반환될 때까지 봉쇄됨

-  **mutex Lock을 사용한 임계구역 문제 해결 방안**

  ```c
  do { 
       [ lock을 획득 ] 
        critical section 
       [ lock을 반환 ] 
        remainder section 
  } while(true); 
  ```

- **acquire ( )**  **: lock 획득 함수의 정의** 

  ```c
  acquire(){  
       while( !available) 
            ; /* busy wait */ 
       available = false; //락을 획득
  } 
  ```

- **release ( )**  **: lock 반환** 

  ```c
  release(){  
       available = true;
  } 
  ```

**위 두 함수의 호출은 atomically 수행**

---



### Spin Lock

- busy waiting 방식의 mutex lock. 즉, 자원 점유 가능할 때까지 while 돌며 대기.

- 문맥교환이 일어나지 않음. —> 자원의 점유/해제가 짧은 시간안에 해결가능할 때 적절

  #### **spinlock의 단점** 

  - **busy waiting (spinlock) >> cpu 사이클 낭비** 

  - 프로세스가 임계구역에 있는 동안 임계구역에 들어가기 원하는 다른 프로세스들은 acquire( ) 함수를 호출하는 반복문을 계속 실행 

  - 즉, **lock 이 가용해지기를 기다리면서 프로세스가 계속 회전**을 함 (spinlock) 

  ​     **: test_and_set( ) 과 compare_and_swap( )에서도 spinlock 발생**

  

  #### **spinlock의 장점**

  - lock을 기다리는 동안 상당한 시간을 소모하는 **context-switching을 전혀 필요로 하지 않는다**. 
    - **=> 프로세스들이 짧은 시간 동안만 락을 소유할 것으로 예상되면 spinlock이 유용.**
  - **멀티 코어 프로세서 시스템**에서 많이 사용.  



----

#### Mutex VS SpinLock

- 만약, 임계 구역(Critical Section)이 잠겨있어서 진입을 하지 못하게 되면 풀릴때까지 기다린다. 이 때 [문맥 교환(Context Change)](https://ko.wikipedia.org/wiki/문맥_교환)이 일어난다.

  - 즉, 해당 Process는 CPU의 자원을 점유하지 않는다.

  - 이 특성이 Spin-Lock과 다른 점이다.

---

#### 세마포어 VS 뮤텍스

- 자원의 개수가 여러개일 경우 사용. 외부변수(세마포 변수)는 이진세마포어랑 달리 1 이상의 값이 가능. 
- 세마포는 Lock의 제어를 OS가 함. 
- 뮤텍스는 각 스레드가 lock을 소유/해제한다.

---

#### 세마포 VS 스핀락

- **스핀락**은 자칫하면 발견하기 어려운 타이밍 오류를 야기할 수 있다. 가령 사용자의 실수로 인하여 wait( ) => do cs => signal( );  순이 아니라 뒤바뀌거나 wait만 두군데 있는 경우 교착상태 발생 



### Semaphore

- mutex와 유사하게 동작하지만 프로세스들의 행동을 더 정교하게 동기화
- 세마포 변수 (S) 를 사용하여 OS 레벨에서 자원의 Lock/Unlock을 통제
- **세마포** **S** 
  - 정수변수, 초기화를 제외하고는 단지 두 개의 표준 원자적 연산인 wait( )와 signal( ) 로만 접근 가능. 



**wait( )**

```c
wait(S) { 
     while(S<= 0) 
          ; //busy waiting 
     S--; 
} 
```

- **한 스레드가 세마포 값을 변경**하면 **<u>다른 어떤 스레드도 동시에 동일한 세마포 값을 변경할 수 없다.</u>**
  - wait(S)의 경우, S의 정수값을 검사하는 작업(S<=0)과 그에 따라 실행될 수 있는 변경(S--)하는 작업 또한 인터럽트 되지않고 실행되어야 한다.

signal( )**

```c
signal(S){ 
     S++; 
} 
```

- 세마포의 정수 값을 변경하는 연산은 반드시 분리되지 않고 수행
- **한 스레드가 세마포 값을 변경**하면 **<u>다른 어떤 스레드도 동시에 동일한 세마포 값을 변경할 수 없다.</u>**



### **세마포 사용법**

##### OS는 counting 세마포와 binary 세마포를 구분. 

- 1) 카운팅 세마포의 값은 제한 없는 domain(영역)을 갖는다. 
  - **유한한 개수를 가진 자원에 대한 접근을 제어**하는데 사용될 수 있음. 
  -  세마포는 가용한 자원의 개수로 초기화됨. 
  - 각 자원을 사용하려는 프로세스는 세마포에 **wait( ) 연산**을 수행하며, 이 때 세마포의 값은 감소 **(S--)** 
  - 프로세스가 자원을 방출할 때는 **signal( ) 연산** 수행하고 세마포는 증가 **(S++)** 
  -  세마포의 값이 0이 되면 모든 자원이 사용 중임을 나타냄. 
  - 이후 자원을 사용하려는 프로세스는 세마포값이 0보다 커질 때까지 봉쇄. 

- 2) binary 세마포의 값은 0과 1사이의 값만 가능. -- mutex lock과 유사하게 동작. 

- ##### 동기화 문제 해결을 위한 세마포 

  ex) P1은 S1 명령문을, P2는 S2명령문을 병행하게 수행하려는 두 프로세스를 고려 

  ​      또한 S2는 S1이 끝난 뒤에만 수행되어야 한다고 가정. 

  ​      이 문제에서 P1과 P2가 세마포 synch를 공유하도록 하고, synch는 0으로 초기화한다.   

### **세마포 구현**

​     : Busy waiting 이슈는 세마포 연산 wait( ) 와 signal( ) 에서도 같은 문제. 

​     : 바쁜 대기를 해야 하는 필요성을 극복하기 위해, wait( )와 signal( ) **세마포 연산의 정의**를 다음과 같이 변경한다. 



1. Process가 **wait( ) 연산**을 실행하고 **세마포 S 값이 양수가 아닌** 것을 발견하면 --> Process는 반드시 대기 

2. Busy waiting 대신에 Process는 **스스로를 봉쇄(blocking)**시킬 수 있음.  

3. Blocking 연산으로 해당 프로세스는 세마포에 연관된 Ready Queue에 넣고 프로세스의 상태를 wait로 전환. 

4. 제어가 CPU 스케줄러로 넘어가고, 스케줄러는 다른 프로세스를 실행하기 위하여 선택. 

5. 세마포 S를 대기하면서 봉쇄된 프로세스는 다른 프로세스가 signal( ) 연산을 실행하면 재시작되어야 함. 

6. **wakeup( ) 연산**에 의해 프로세스가 재시작됨. 

7. 위 연산시 프로세스의 상태를 대기상태에서 준비 완료 상태로 변경 

8. 프로세스는 준비완료 큐에 넣어짐 (CPU 스케줄링 알고리즘에 따라 이후 실행 여부 판단) 

​     

#### **세마포 구조체 정의**

```c
typedef struct { 
     int value;          //세마포 S의 S역할. 자원의 총 개수
     struct process *list;          //세마포 대기 큐
} semaphore;
```

- 각 세마포는 한 개의 정수 value와 프로세스 리스트 (*list)를 가진다. 프로세스가 세마포를 기다려야 한다면, 이 프로세스를 세마포의 프로세스 리스트에 추가한다. 

- signal( )연산은 프로세스 리스트에서 한 프로세스를 꺼내서 그 프로세스를 깨워준다.(wakeup()) 



#### **wait( )연산 정의**

```c
void wait(semaphore *S){ 
     S-> value--;
     if(S->value < 0){ 
          [이 프로세스를 S->list에 넣는다.] //ex) S.list.add(P); 
          block();	// block() 연산은 자기를 호출한 프로세스를 중지시킴.
     }
}
```



**signal( ) 연산 정의**

```c
void signal(semaphore *S){ 
     S->value++;
     if (S->value <= 0){ 
         [ S->list로부터 하나의 프로세스 P를 꺼낸다. ] // ex) S.list.remove(P);
         wakeup(P);	//wakeup(P) 연산은 봉쇄된 프로세스 P의 실행을 재개시킴
     }
}
```



##### 동기화 문제들 

- 우선순위 역전 문제 
- Indefinite blocking (무한봉쇄)
- Starvation 
- 유한버퍼 문제 (고전적 문제 )



---

## 모니터

- 뮤텍스와 조건변수;Conditional Variable(Queue)를 가지고 있는 동기화 매커니즘

- Java의 Object 클래스들이 공통으로 갖는 메서드 wait() / notifyAll() / notify() 메서드들이 조건변수의 역할.
- Java는 상호배제를 위한 구현체로 synchronized 키워드를 제공
- synchronized가 메서드 선언되어있고, 스레드A가 이미 lock을 획득하여 임계구역을 수행중이라고 가정
- 스레드 B가 동일한 임계구역 진입을 위해서는 Object의 Lock을 획득해야 함.
- 스레드 B는 이 Lock이 반환될때까지 대기해하는데, 이때 모니터를 사용.
- 스레드A가 Lock 반환시 스레드B가 Lock을 획득하여 임계구역을 실행. 
- 별도로 명시적인 Monitor를 구현할 수도 있다.
- Monitor는 이렇게 Mutex(Lock)과 Condition Variables을 이용해서 Mutual Exclustion을 해결



#### 모니터 vs 뮤텍스

- 뮤텍스와 달리 **하나의 프로세스 내의 다른 스레드 간에 동기화할때 사용**된다.
  - 뮤텍스는 다른 프로세스 간에 동기화에 사용
- Mutex는 보통 OS 커널, 프레임워크, 라이브러리에 의해 제공됨 (무겁고 느림)
- 모니터는 프레임워크나 라이브러리 자체에서 제공. (경량, 빠름)





---



## 교착상태

- 특징

  - 다중프로그래밍 환경에서는 여러 프로세스들 간의 한정된 자원 사용 경쟁이 발생

  - **대기중인 프로세스들이 결코 다시는 특정 자원의 상태를 변경시킬수 없는 상태.**

  - **요청한 자원들이 다른 프로세스에 의해 점유되고 있고, 그 프로세스들도 자원을 점유한 채 대기상태인 상황**

    

- 데드락 발생조건

  - ##### 상호배제 / 점유하며 대기 / 비선점 / 순환대기 (꼬리물며 상대방이 필요한 자원점유하며 대기)

  - **자원할당 그래프**에서 프로세스와 자원 간에 자원 요청간선과 자원 할당간선으로 **사이클 존재시 데드락 발생 가능** (필요조건. **반드시 발생하는건 아님)**

#### 교착상태 처리방법 4가지 

| 구분                      | 세부 내용                                                    |
| ------------------------- | ------------------------------------------------------------ |
| 교착상태 예방(Prevention) | 교착상태의 필요조건을 부정함으로써 교착상태가 발생하지 않도록 미리 예방하는 방법 (ex 환형대기, 비선점, 점유와 대기, 상호배제 4가지 부정) |
| 교착상태 회피(Avoidance)  | 교착상태 가능성을 배제하지 않고 적절하게 피해나가는 방법 (ex 은행원 알고리즘) |
| 교착상태 탐지(Detection)  | 교착상태 발생을 허용하고 발생 시 원인을 규명하여 해결하는 방법 (ex 자원할당 그래프) |
| 교착상태 복구(Recovery)   | 교착상태 발견 후 환형대기를 배제시키거나 자원을 중단하는 메모리 할당 기법 (ex, 선점, 프로세스 중지(희생자 선택)) |

- 예방

  - 자원의 요청되는 방식을 제한하여 예방

- #### 회피

  - 방법 1) 프로세스가 **일생동안 요구하고 사용할 자원에 대한 부가정보 미리 제공**받아서 회피 

  - 방법 2) 각 프로세스 별로 필요한 자원을 요청할 경우, **자원의 유형별로 할당 상한**을 걸어둠

  - **구체화 방법1)**

    - 순환대기 상황이 발생하지 않도록 자원 할당 상태를 검사.

    -  **자원할당** **그래프에** **예약간선을** 거는 방법

      

  - **구체화 방법2)**

    - **은행원 알고리즘** 

- 탐지

  - 예방/회피 없이 허용하는 경우 데드락 탐지 가능해야 

- 회복

  - 예방/회피 없이 허용하는 경우 회복 알고리즘 있어야 함

- 보통은 문제를 무시, 교착상태가 발생하지 않는 척 무시하는 방식으로 적은 비용으로 해결 



자원할당 그래프 with 예약간선

- 요청 간선과 할당간선에 예약간선을 새로이 추가.
- 시스템에 **자원이** **반드시 미리 예약되어야** 함에 유의한다.
- 예약간선 Pi —> Rj는 Pi가 미래에 자원 Rj를 요청하는 것을 의미. 
- 프로세스 **Pi와 연관된 모든 간선들이 <u>요청간선이 아니라 예약간선 일 때만</u>** 예약 간선 Pi --> Rj를 그래프에 추가하도록 허용
- 프로세스 Pi가 자원 Rj를 요청한다고 가정시, **요청간선 Pi -----> Rj 를 할당간선 Rj -> Pi 로 변환해도 자원 할당 그래프에 사이클을 형성하지 않을 때에만 요청을 허용**
  - **사이클 탐지** 알고리즘을 이용해 안전성을 검사함에 있어서 **n^2 차수의 연산**이 필요 (n은 프로세스의 수)
- Pi가 자원 Rj 요청시 예약간선 Pi—> Rj는 요청간선으로 변환된다. 
- Pi가 자원 Rj를 방출할 때, 할당 간선 Rj->Pi는 예약간선 Pi----->Rj로 다시 변환

### **은행원 알고리즘 (Banker's Algorithm)**

- 자원할당 그래프 알고리즘은 종류마다 자원이 여러개씩 존재하면 사용할 수 가 없음.  
  - 뱅커스 알고리즘이 이 경우에 사용됨.  

- 자원 할당 그래프 알고리즘보다는 효율성이 다소 떨어짐. 
- 교착상태에 빠질 가능성이 있는지 판단하기 위해 상태를 '안전상태(safe state)'와 '불안전상태(unsafe state)'로  나눈다. 
- **은행원 알고리즘에서 운영체제는 안전상태를 유지할 수 있는 요구만을 수락하고 불안전 상태를 초래할 사용자의 요구는 나중에 만족될 수 있을 때까지 계속 거절**

#### **뱅커스 알고리즘** 

- 프로세스가 시작시 <u>프로세스가 가지고 있어야할 자원의 최대 개수를 자원 종류마다 미리 신고</u>해야 함. 

- 시스템이 <u>그 요청을 들어줄 때, 계속 안전 상태에 머무르는지 여부를 판단</u>하여, **안전하면 요청을 허용**. / else 대기 

​      

 은행원 알고리즘을 구현하기 위한 자료구조들. n은 프로세스의 수, m은 자원의 종류 

```tex
Available : 각 종류 별로 가용한 자원의 개수를 나타내는 벡터. 크기는 m
   Available[j] = k라면 현재 Rj를 k개 사용할 수 있다는 뜻.

Max : 각 프로세스가 최대로 필요로 하는 자원의 개수를 나타내는 행렬. 크기는 n x m 
   Max[i,j] = k 라면 Pi가 Rj를 최대 k까지 요청할 수 있음을 의미.

Allocation : 각 프로세스에 현재 나가있는 자원의 개수를 나타내는 행렬. 크기가 n x m
   Allocation [i, j ] = k 라면 현재 Pi가 Rj를 k개 사용 중임을 의미.

Need : 각 프로세스가 향후 요청할 수 있는 자원의 개수를 나타내는 행렬. 크기는 n x m 
   Need[i, j]  = k 라면 Pi가 향후 Rj를 k개까지 더 요청할 수 있음을 뜻함.

Need[i, j] = Max[i , j] - Allocation [i, j] 로 계산한다.

//
Allocation과 Need 행렬의 각 row를 벡터로 취급, 이들 각 행 벡터들을 각각  Allocation_i, Need_i와 같이 표기.
```



#### 뱅커스 알고리즘 - 안전성 알고리즘

1) Work과 Finish의 벡터 크기가 각각 m, n 이다.

최초에 Work = Available이고 Finish[i] = false (i=0… n-1)로 초기화한다.

2) 다음의 조건을 만족하는 인덱스 i를 찾아라

​	a. 아직 끝나지 않았고 (Finish[i] == false)

​	b. 프로세스 i의 이후 요청 자원 개수가 현재 자원 보유량보다 작은 경우 (Need_i <= Work)

- 이러한 조건을 만족하는 i  가 존재하지 않으면 **4)** 로 이동

3) 만약 i의 작업이 끝났다면 다음의 조치를 취하고 **2)** 로 이동한다.

​	쓰던 자원을 가용자원으로 변환 : Work = Work + Allocation_i 로 갱신한다.

​	i번째 프로세스 완료로 갱신 : Finish[i] = true 

4) 만약 **모든 프로세스에 대해  Finish[i] == true 면** **system은 안전상태에** 놓여있다.



#### 뱅커스 알고리즘 - 자원요청 알고리즘

- Request i 는 프로세스 Pi의 요청 벡터라고 하자. `Request_i [ j ] == k `라면 Pi가 Rj를 k개까지 요청하고 있음을 뜻한다. 

**1.** 만약 ***Request****i* ≤***Need****i*  이면 go to step 2. 그렇지 않으면 시스템에 있는 개수보다 많이 요청했으므로 오류로 처리.  

**2.** 만일 ***Request****i* ≤ ***Available,*** go to step 3. 그렇지 않으면 요청한 자원이 당장은 없으므로 Pi는 대기해야 한다. 

**3.** 마치 시스템이 Pi 에게 자원을 할당해준것처럼 시스템 상태정보를 아래처럼 바꾸어 본다. 

​    ***Available*** = ***Available***–***Request****i* ; 

​    ***Allocation****i* = ***Allocation****i* + ***Request****i* ; 

​    ***Need****i* = ***Need****i* –***Request****i* ; 

- 이렇게 **새로 바뀐 상태가 안전하다면** Pi에게 여기에 반영된 정보대로 **자원을 할당**
- 새로운 상태가 <u>불안전하다면,</u> 위의 자원 할당 상태는 <u>원 상태로 복원</u>되고, Pi는 ***Request*** *i*  가 만족되기까지 <u>대기</u>한다.



------

----



## 8. 메모리전략

- Stall 현상 : 메모리 버스를 통해서 전송되는 메인 메모리의 속도가 느려서, 메인메모리 접근을 완료하기 위해 cpu clock cycle이 많이 필요한 경우, cpu가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연되는 현상.
  - 물리적으로 메모리 접근의 속도를 개선 
    - 캐시 추가(cpu와 주 메모리 사이에 빠른 속도의 메모리 )
  - 올바른 동작을 보장하도록 HW 지원 : **base / limit 활용한 보호기법**
    - 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장
    - 이 때, 개별 메모리 공간을 분리하기 위해 특정 프로세스만 접근할 수 있는 legal 메모리 주소 영역을 설정하고, 프로세스가 legal 영역에만 접근하도록 하는 방식으로 **개별 프로세스 별 메모리공간을 서로 보호**
    - ex) base : 300040이고, limit : 120900이면, 프로그램은 300040 ~ 420940까지의 모든 주소만 접근. 
    - base & limit 레지스터는 여러 특권 명령을 사용하는 OS에 의해서만 load되도록 하여, user application이 레지스터의 내용을 변경하는 것을 방지.

-----



#### **Logical - Versus Physical - Address Space**

​    1) **Logical Address** : CPU가 생성하는 주소. 

​    2) **Physical Address** : 메모리가 취급하게 되는 주소, 메모리 주소 레지스터(MAR)에 주어지는 주소. 

- **user application은 physical address를 절대 알 수 없음.** 

##### 컴파일 시 바인딩 기법 

- 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대코드**를 생성

##### Load 시 바인딩 

- 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면 컴파일러는 일단 **이진코드를 재배치 가능 코드**로 만들어야 함. 심볼과 진짜 번지수와의 **바인딩은 프로그램이 주 메모리를 실제로 적재되는 시간에** 발생

`컴파일 시 바인딩`과 `적재 시의 바인딩` 기법의 경우, **논리주소==물리주소**가 된다. 



##### 실행 시간 바인딩

- binding이 **runtime**까지 허용
  - 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있다

  `실행 시간 바인딩 기법` 에서는 **논리주소 != 물리주소.** 

- 이러한 경우, 논리주소를 **가상주소**( virtual address ) 라고 한다.  (논리주소나 가상주소를 동일하게 사용) 



----

##### 동적 로딩

- 메모리 공간의 효율적 이용을 위해 동적 적재
  - 각 루틴은 실제 호출 전에는 메모리에 올라오지 않고, 재배치 가능한 상태로 디스크에서 대기
- 프로세스의 크기 > 메모리의 크기 일때 용이
- 루틴이 필요한 경우에만 적재됨. 오류 처리 루틴과 같이 많은 양의 코드를 필요하는 경우 유용함. 
- OS가 동적 적재를 구현하는 라이브러리 루틴을 제공하기도하나, 운영체제로부터 특별한 지원은 필요없음 
- 사용자가 프로그램의 설계를 책임져야 함. 

##### 정적 로딩 

- 프로세스가 실행되기 위해 프로세스 전체가 미리 메모리에 올라와 있어야 함.
- 프로세스의 크기<메모리의 크기



**동적 연결 라이브러리 (DLL)**

- 사용자 **프로그램이** **실행시**, 사용자 프로그램에 **연결되는 라이브러리.** 
  -  운영체제에 따라 static linking만 지원하기도 함. 

- 동적 적재의 개념과 유사. 동적 적재가 loading이 실행(execution)까지 미뤄졌던것과 유사하게, **linking이 실행 시기까지 미뤄진다.** 

- 주로 시스템 라이브러리에서 사용 

- 경우에 따라서 이미 메모리에 로드 되어있거나, 디스크로부터 가져와야 함.  

**동적 링킹의 장점**

- 라이브러리 루틴을 바꿀 때 유용.  

- 갱신된 라이브러리 버전 사용에 있어서 모든 프로그램이 새 라이브러리 사용을 위해 새로운 링크를 할 필요가 없음.  

- 단, 버전에 대한 정보가 프로그램과 라이브러리 내에 각각 포함되어야 함. 



```tex
[ 정적라이브러리 ]
[장점]
- 동적(공유)라이브러리에 비해 실행 속도가 빠르고 배포에 제약이 없음
[단점]
- 다만, 해당 라이브러리를 필요로 하는 모든 경우 같은 정적 라이브러리가 링크되기 때문에 배포 파일들의 사이즈가 커짐
- 그러므로 하드디스크 공간도 더 차지하고 메모리도 더 많이 차지함
- 그러나 유닉스 시스템의 경우 그때그때 필요한 부분만 메모리에 로딩하는 demand paging을 사용하기 때문에 정적인 라이브러리의 메모리 사용률과 공유 라이브러리의 메모리 사용률의 차이가 크지 않음
```

```tex
[ 동적(공유)라이브러리 ]
- 라이브러리를 여러 프로그램이 사용될 때 라이브러리 코드 영역을 공유
[ 장점 ] 
- 각각의 프로그램의 사이즈가 작아진다는 장점
- 메모리 효율이 좋음

[ 단점 ] 
- 실행속도가 느리고 실행파일이 배포된 시스템에 컴파일시 사용된 메이저 버전의 동적 라이브러리가 없거나 혹은 있으도 메이저 버전이 다르면 프로그램이 작동되지 않음

[ 공유 라이브러리 ] 
- 이런 경우 만약을 대비해 공유라이브러리도 함께 배포하면 하나만 로딩해서 여러 프로세스가 공유해서 사용
- 해당 공유 라이브러리를 필요로 하는 프로세스가 하나라도 있으면 메모리에 로딩되어서 해당 라이브러리를 필요로 하는 프로세스가 하나도 없을 때까지 계속 메모리에 남아있음
- 라이브러리와 실행바이너리 사이의 연결 시간 및 실행시간이 상대적으로 커짐
```



----



### 스와핑

- 모든 프로세스의 **물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리 크기보다 큰 경우에도 동시 실행을 가능하게 해주는 다중 프로그래밍의 기법** 중 하나.  

  - 프로세스 실행 중 <u>임시로 예비 저장장치(backup store)로 내보내어졌다가</u> 실행을 계속하기 위해 <u>다시 메모리로 되돌아</u> 올 수 있음.  

  #### [1] 기본 스와핑 작동 방식

  - **( 현재 쓰지 않음. 변형 스와핑을 쓰기때문)** 

  - <u>메인 메모리</u>와 <u>예비 저장장치(보통 빠른 디스크 사용</u>) 사이에 프로세스를 이동

  - 이 저장장치의 크기는 모든 사용자의 메모리 이미지를 저장할 수 있을 만큼 커야 함

  - 메모리 이미지에 대한 직접 접근이 가능해야 함

  -  **작동 방식** 

    ​     1) 시스템이 실행 준비된 모든 프로세스를 모아 `레디 큐`에 보관. 

    ​     2) CPU 스케줄러가 다음 프로세스를 고르기 위해 `Dispatcher`를 호출. 

    ​     3) 디스패처는 레디 큐에 있는 다음 프로세스가 메모리에 올라와 있는지를 확인. 

    ​     4) 만약 안 올라와있으면 <u>디스크에서 다음 프로세스를</u> 불러옴. 

    ​     5) **프로세스를 위한 공간이 메모리에 없다면 공간을 만들기 위해 현재 메모리에 올라와있는 프로세스를 내보냄 (swap out)** 

    ​     6) 원하는 프로세스를 불러들임 (swap in)  

    ​     7) CPU의 모든 레지스터를 실행해야 할 첫 프로세스의 것으로 다시 적재 

    ​     8) CPU 제어를 그 프로세스에게 넘김. 

  #### 기본 스와핑 단점

  - 문맥 교환 시간 (context-switch time)이 상당히 오래 걸림.
  - 스왑 시간의 대부분은 디스크 전송 시간
  - 전송 시간은 스왑될 메모리의 크기와 비례

  ####  **스와핑의 제약**

  - 한 프로세스를 스왑하기 원하면 해당 프로세스는 완전히 휴지 상태에 있음을 확인해야 함. 

  ​      ex) I/O signal을 주고받는 동안이면, swap하면 안됨. 

  ​     ex) 입출력 장치가 바빠서 프로세스 입출력이 ready queue에 들어간다고 가정. 

  ​     		프로세스P1의 스왑아웃과 P2의 스왑인 시 입출력을 요청한 P1이 아닌 P2에 대해 입출력을 사용하려 할 것. 

   		    => 1) 입출력이 종료되지 않은 프로세스를 스왑하지 않거나, 2) 입출력은 항상 프로세스로 직접하지 않고 OS의 버퍼와만 하도록 규정       

  - OS와 프로세스 사이의 전송은 단지 프로세스가 스왑되어 들어온 상태에서만 수행하면 됨.  

    ​      => 이중 버퍼링 자체만 고려하면 오버헤드를 일으킬 수 있음. 

  #### [2] 연속 메모리 할당

  - 각 프로세스가 다음 프로세스를 포함하는 영역과 연속된 하나의 메모리 영역을 차지함

  #### **메모리 Protection**

  - 프로세스가 자신이 소유하지 않은 메모리를 접근할 수 없게 강제할 수 있음.  
    - 시스템이 limit 레지스터와 relocation(base) 레지스터를 가지고 있으면 가능 
    - 재배치 레지스터는 가장 작은 물리 주소의 값을 저장.  
    - 상한 레지스터는 논리 주소의 범위 값을 저장. (ex 재배치 레지스터 = 10040, limit 레지스터 = 74600)

  ### 메모리 할당

  #### 고정 분할 방식

  - MFT 
    -  모든 메모리 영역을 균일한 크길로 분할(partition) 
    -  한 파티션이 비게 되면 한 프로세스가 input 큐에서 선택되어 빈 파티션에 들어온다.  
  - MVT 방식 
    - 배치 환경에서 고정된 크기의 분할 영역을 사용하는 방법 

  #### 가변 분할 방식

  - OS는 메모리의 어떤 부분이 사용되고 있고, 어떤 부분이 사용되지 않고 있는가를 파악할 수 있는 테이블을 유지. 

    - 초기에 모든 메모리 공간은 한 개의 큰 사용 가능한 블록(Hole)으로 간주됨.       

     1) 프로세스가 시스템에 들어오면, 일단 input 큐에 넣음. 

     2) OS가 프로세스의 메모리 요구량, 사용 가능한 메모리 공간등을 고려하여 메모리 공간을 할당.  

     3) 프로세스가 공간을 할당받게 되면, 이후로는 CPU를 할당 받기 위해 경쟁 

     4) 프로세스가 끝나면 메모리를 반납. 

     5) 운영체제는 input 큐에 있는 다른 프로세스로 이 공간을 채움. 

    

  #### **동적 메모리 할당 문제 해결책 3가지** **(괄호 순서대로 모의 실험 효율성)** 

  ​     **1) First - fit (1)**

  - <u>첫 번째 사용 가능한 가용 공간을 할당</u>. 
  - 집합의 시작에서부터 검색하거나 지난 검색 종료시점에서 검색 시작. 충분히 큰 가용 공간 찾으면 검색 종료       

  ​     **2) Best - fit (2)**

  - <u>사용가능한 공간들 중에서 가장 작은 것</u>을 택함.  

  - 리스트가 크기순으로 정렬되어있지않으면 전 리스트를 검색 

  - 아주 작은 가용 공간이 남는다.       

  #####      3) Worst - fit (3) 

  - 가장 큰 가용 공간을 택함. 

  - 남는 자유 공간이 충분히 커서 다른 프로세스에게 유용하게 할당. 

  - 자유 공간들이 크기 순으로 정렬되어있지 않으면, 전 리스트를 다 검색. 

  

  #### **Fregment** 

  -  공간 중 일부가 사용 못하게 되는 부분. 

  #### **1)** **external fragmentation.** 

  - 프로세스들이 메모리에 적재되고 제거 되는 일이 반복되다 보면 어떤 자유 공간은 너무 작은 조각이 되어 버림. 
  - **외부 단편화는 유휴 공간들을 모두 합치면 충분한 공간이 되나, 그것들이 너무 작은 조각들로 여러 곳에 분산되어 있을 때 발생**. 
  - 최악의 경우, 모든 프로세스 사이마다 못 쓰게 된 자유 공간 존재 가능.

  ####  **2)** **internal fragmentation** **(외부단편화 해결 방법으로 인한 부수적인 문제)** 

  - 18,464 B 크기의 자유 공간을 가정. 어느 한 프로세스가 18,462B를 필요로 할 때, 요구된 블록을 정확하게 할당하다보면 2B보다 더 큰 부담을 시스템이 지게 된다.  

  - 일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고, 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수 배(2^n) 로만 해주는 것이 보통. 

  - 이 경우, **할당된 공간은 요구된 공간보다 약간 더 클수 있음.** 이들 **두 크기 사이의** **사용되지 못하고 남는 부분**을 내부 단편화라고 한다.  

  #### **3)** **압축; Compaction** ( 외부단편화 해결 방법 ) 

  - 메모리의 모든 내용을 한 군데로 몰고 모든 자유 공간들을 다른 한 군데로 몰아서 큰 블록을 만드는 것.  

  - 항상 가능하지는 않음. 재배치가 어셈블 또는 loading 시에 정적으로 행해진다면, 압축 불가. 

  - <u>프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만</u> 가능. 

----



### 세그먼테이션

- 프로그래머가 **인지하는 메모리의 모습**을 **실제 물리 메모리의 모습으로 변환해주는** 메모리 기법

- **세그먼트 테이블**

  ​           : 사용자 정의의 2차원 주소를 1차원 물리주소로 mapping 함. 

  ​           : 각 항목은 segment base, segment limit를 지님. 

  ​           : segment Table은 segment base/segment limit 의 쌍으로 이루어진 배열. 

  ​     **세그먼트 base**

  ​          : 각 세그먼트의 시작주소를 나타냄 

  ​     **세그먼트 limit**

  ​          : 각 세그먼트의 길이를 명시 

  ​    **- 논리주소의 구성과 사상 (segment -> physical address space)**

  ​          \- 세그먼트 번호 s와 그 세그먼트 내에서의 offset(변위) d로 구성 

  ​          \- 세그먼트 번호 s는 세그먼트 테이블에 대한 index로 사용됨. 

  ​          \- 변위 d는 0과 세그먼트 limit사이의 값. (otherwise, trap) 

  ​          \- 범위 안의 변위에 대해 세그먼트 base와 합해져서 원하는 바이트의 실제 주소가 얻어짐. 

### 페이징

- 세그멘테이션과 마찬가지로 **프로세스가 적재되는 물리 주소공간이 연속적이지 않아도 적재를 허용하는 방법**. 

- 세그먼테이션과 달리, **외부 단편화를 방지**하고 단편화에 따른 **압축 작업이 필요없음**.

- 스왑아웃되는 <u>다양한 크기의 세그먼트를 예비 저장장치에 저장해야 하는 심각한 문제도 해결</u>함.  

​     => 왜냐하면 <u>**예비 저장장치**는 주 메모리와 같이 동일한 단편화 문제를 보유</u>하고 있으며, 접근 속도가 느리므로 <u>압축하는 것이 불가능</u>함. 

- 페이징 그 자체는 동적 재배치의 한 형태
- **페이징 기법을 사용하면 외부 단편화가 발생되지 않는다.** (모든 놀고 있는 프레임이 프로세스에게 할당될 수 있음.) 
- But, **내부 단편화가 발생**. (할당은 항상 Frame의 정수 배로 할당되므로) 

- **페이징은 context -switch 시간을 증가**시킴

#### 	페이징 **기본 방법**

- **Frame** : 물리 메모리를 나누는 동일 크기의 블록. HW에 의해 정의 
  - 프로세스 실행시 그 프로세스의 페이지는 **File system** 또는 **예비 저장장치로부터** 가용한 주 **메모리 Frame으로 적재**된다.
  - 예비 저장장치는 메모리 Frame 혹은 Frame의 묵음인 Cluster와 동일한 크기의 고정크기 블록으로 나누어진다.  
  - ex) **논리 주소 공간**이 물리 주소공간으로부터 완전히 분리되었기때문에 물리 메모리의 크기가 2^64보다 적게 장착된 시스템에서도 프로세스가 64bit로 이루어진 논리 주소 공간을 사용할 수 있음. 

- **page** : 논리 메모리를 나누는 동일 크기의 블록.  HW에 의해 정의 
  - CPU에 나오는 모든 주소는  **페이지 번호(p)**와 **페이지 변위(d : offset)** 두 개의 부분으로 나누어짐. 
  - **페이지 번호**는 page table을 액세스할 때 사용된다.
  - **페이지 테이블**은 주 메모리에서 <u>각 페이지가 점유하는 주소(페이지 주소)</u> 를 갖고 있음.  
  - 물리주소 = 페이지 주소 + **페이지 변위(offset)**

- 예시 )논리 주소 공간의 크기가 2^m이고, 페이지가 2^n 크기라면 

  - |  페이지 번호(p) = m-n | 페이지 오프셋(d) = n |
  - 논리 주소의 상위 m-n 비트는 페이지 번호(p)를 나타냄. 
  - 하위 n비트는 페이지 offset을 의미.       
  - `p`는 **페이지 테이블에 대한 인덱스로 사용**되고, `d`는 **페이지 내에서의 offset**으로 사용 된다. 

  

-  [그림 8.12] :  4B의 페이지 크기와 32 B의 물리 메모리 (8 page)를 사용하여 논리주소에서 물리메모리로 사상되는 예 //  논리적 페이지 0~3에 대해 페이지 테이블은 [5,6,1,2] 이다

​     1) 논리주소 0 (a) : page 0, `offset 0`을 의미.  

​     2) 페이지 테이블을 index로 찾아서 페이지 0이 `프레임 5`에 있다는 것을 알아낼 수 있음.  

​     3) 논리주소 0은 실제주소 20(=`5` x 4 + `0`)으로 mapping된다. 

​     4) 논리주소 3(d, page 0, offset 3)은 실제 주소 23 (=(5x4)+3)으로 매핑된다.  

​     5) 논리주소 4(e, page 1, `offset 0`)은 페이지 1이 `Frame 6`으로 mapping되므로 실제 주소 24 ( = `6`x4 +`0`)으로 매핑된다. 

​     6) 논리주소 13은 실제주소 9로 매핑됨. 



#### **작은 페이지 vs 큰 페이지 크기**

-  보통 프로세스 당 반 페이지정도의 내부 단편화가 예상됨.  -> **작은 페이지가 내부단편화 줄이는데에 바람직** 

- **But, 페이지 크기가 작아지면** 그에 반비례하여 **페이지 테이블의 크기가 커지고,** Page Table이 차지하는 공간은 낭비가 됨. 
- [ 디스크의 입장 ] 에서는 페이지의 크기가 클 수록 효율적 
- 페이지 메모리 시스템에서 **물리 메모리의 크기**는 **프로세스의 최대 논리적인 크기와는 다르다**. 

​     

#### 일반적으로 페이지 테이블 내의 각 entry는 4Bytes ( 8*4 = 32 bits). 

- 32 bit엔트리 = 2^32개의 물리 페이지 프레임 가리킬 수 있음. 

-  but 프레임크기에 따라 달라질 수 있음.  
  
- 프레임 크기가 4KB(2^12)라면 4Bytes 크기의 엔트리는 2^44 Bytes (=16TB)개의 물리주소를 저장할 수 있음. 
  
- 페이지 테이블 항목에 유지되어야 하는 정보를 포함해야하므로 실제 32bit 페이지테이블은 가능한 최대 크기보다는 작은 물리 메모리를 지정할 수 있음. 

  - 32-bit CPU는 32-bit 주소를 사용하여 프로세스에게 허용된 공간은 2^32B (=4GB). 

  ​          => 따라서 페이징 기법은 CPU 주소 포인터 크기가 제한되는 것보다 더 큰 물리 메모리를 상할 수 있게 함. 



### 페이징을 위한 하드웨어 지원 - TLB

#### 	**TLB (Translation Look-aside Buffer)**

- 특수 소형 하드웨어 Cache (Intel Core i7 CPU의 L1, L2 캐시 등에 존재) 

- 매우 빠른 associative memory(연관메모리)로 구성. 

- 각 항목이 **key(페이지 번호)/value(프레임 번호)** 두 부분으로 구성. 
  - TLB에 페이지를 찾아달라고 요청이 들어오면, 이 찾고자 하는 페이지를 동시에 여러 개의 내부 키(페이지 번호)와 비교.  
  -  페이지 번호가 같은 것이 발견되면 대응하는 프레임 번호를 알려줌 
  - 검색 속도가 빠르고, 명령어 파이프라인의 일부로 동작하여 **성능에 추가적인 손해 없음.** 
  - 파이프라인의 단계 동안 검색을 하기 위해 TLB의 크기는 작게 유지할 수 밖에 없음 (32개~1024개 항목) 

  - 경우에 따라 설계단계에서 cpu에 개별적인 TLB구현하여 TLB 항목의 개수 증가시키는 방법도 존재.       

####      **TLB 사용 방법 (with Page Table)**

​     1) TLB는 페이지 테이블의 일부분만을 저장. (32~1024개) 

​     2) CPU가 논리 주소 생성시 해당 페이지번호가 TLB에 전달. 

​     3) 페이지 번호가 발견되면 해당 프레임 번호를 즉시 알 수 있고, 메모리 접근에 사용됨. 

​     4) 만약 TLB내에 페이지번호가 존재하지 않으면 (TLB Miss), 페이지 테이블에 접근하기 위한 메모리 참조가 일어남. 

​     5) 이 참조는 CPU의 종류에 따라 하드웨어에서 자동적으로 이루어지거나 OS에서 interrupt를 걸어 수행. 

​     6) 프레임번호가 얻어지면 메모리 접근을 위해 사용됨.  

​     7) 새로운 페이지 번호와 프레임번호를 TLB에 추가하여 다음 참조시 매우 빨리 처리 

​     8) 만약 TBL가 full이라면, 기존 항목 중에서 교체될 항목을 선택. 

​          -> 교체 정책은 LRU, 라운드 로빈, 무작위 등등 

​          -> CPU가 직접 교체항목을 선택하거나 OS의 참여를 허용. 

- 몇몇 TLB는 특정 항목을 TLB(중요 커널 등)에 고정시키는데, 이러한 항목들은 TLB에서 제거될 수 없음.  

- TLB에 따라 각 항목에 `ASIDs (Address-Space IDentifiers)`를 저장하기도 함. 
  - ASIDs는 그 TLB 항목이 어느 프로세스에 속했는지 알려주어 그 프로세스의 정보를 보호하기 위해 사용. 

- TLB에서 가상 주소 변환시 현재 수행중인 프로세스의 ASDI가 TLB항목에 있는 ASID와 동일한지 여부 검사. 

​     if Not equal ->  TLB miss로 처리  

​	**ASIDs의 장점**

- 한 TLB안에 여러 프로세스들의 정보를 동시에 함께 보관할 수 있음. 
  - **만약 ASID 지원이 없으면** 새로운 페이지 테이블이 선택될 때마다(새 프로세스가 문맥교환으로 실행 재개시) 다음 실행 프로세스가 잘못 변환을 하지 않도록 하기 위해 **TLB가 전부 flush**되어야 한다. 

#####   Hit ratio 

-  접근하려는 메모리의 번호가 TLB에서 발견되는 비율. 

​    ex) 주 메모리 접근에 100ns 소요된다고 가정시.  

​      if TLB hit,  100ns 소요됨. 

​      else, TLB miss, 페이지 테이블을 접근하여 프레임 번호를 알아냄(100ns)+ 원하는 데이터를 메모리에서 읽음(100ns) = 총 200ns 소요. 

---

---



## 9. 가상 메모리

프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법

사용자 프로그램이 물리 메모리(physical memory)보다 커져도 됨

가상 메모리는 물리 메모리로부터 사용자 관심의 논리 메모리를 분리시켜 메인 메모리를 균일한 크기의 저장 공간으로 구성된 엄청나게 큰 배열로 추상화시키므로 메모리 크기의 제약으로부터 자유로움

- 요구 페이징
- 쓰기 시 복사
- 페이지 교체
- 프레임







## 10.파일 시스템

- 파일 개념
- 디렉터리와 디스크 구조
- 파일 시스템 마운팅
- 할당 방법
- 자유공간 관리

## 대용량 저장장치

- 디스크 구조/ 부착/스케줄링/관리/스왑공간 관리
- RAID 구조